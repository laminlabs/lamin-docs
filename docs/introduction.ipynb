{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![stars](https://img.shields.io/github/stars/laminlabs/lamindb?logo=GitHub&color=yellow)](https://github.com/laminlabs/lamindb)\n",
    "[![pypi](https://img.shields.io/pypi/v/lamindb?color=blue&label=pypi%20package)](https://pypi.org/project/lamindb)\n",
    "[![cran](https://www.r-pkg.org/badges/version/laminr?color=green)](https://cran.r-project.org/package=laminr)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "```{include} includes/preface.md\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track notebooks & scripts\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/BunYmHkyFLITlM5MYQck.svg\" width=\"330px\" style=\"background: transparent; margin-top: 1em;\" align=\"right\">\n",
    "\n",
    "LaminDB provides a framework to transform datasets into more useful representations: validated & queryable datasets, machine learning models, and analytical insights. The transformations can be notebooks, scripts, pipelines, or functions.\n",
    "\n",
    "The metadata involved in this process are stored in a _LaminDB instance_, a database that manages datasets in storage. For the following walk through LaminDB's core features, we'll be working with a local instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```bash\n",
    "lamin init --storage ./lamin-intro --modules bionty\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "library(laminr)\n",
    "lamin_init(storage = \"./laminr-intro\", modules = c(\"bionty\"))\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin init --storage ./lamin-intro --modules bionty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What else can I configure during setup?\n",
    "\n",
    "1. You can pass a cloud storage location to `--storage` (S3, GCP, R2, HF, etc.)\n",
    "    ```python\n",
    "    --storage s3://my-bucket\n",
    "    ```\n",
    "2. Instead of the default SQLite database pass a Postgres connection string to `--db`:\n",
    "    ```python\n",
    "    --db postgresql://<user>:<pwd>@<hostname>:<port>/<dbname>\n",
    "    ```\n",
    "3. Instead of a default instance name derived from the storage location, provide a custom name:\n",
    "    ```python\n",
    "    --name my-name\n",
    "    ``````\n",
    "4. Mount additional schema modules:\n",
    "    ```python\n",
    "    --modules bionty,wetlab,custom1\n",
    "    ```\n",
    "\n",
    "For more info, see {doc}`/setup`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} If you decide to connect your instance to the hub, you will see data & metadata in a UI.\n",
    "\n",
    "<a href=\"https://lamin.ai/laminlabs/lamindata\">\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/YuefPQlAfeHcQvtq0000.png\" width=\"700px\">\n",
    "</a>\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now track the notebook that's being run.\n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "import lamindb as ln\n",
    "\n",
    "ln.track()  # track the current notebook or script\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "library(laminr)\n",
    "ln <- import_module(\"lamindb\")  # instantiate the central `ln` object of the API\n",
    "\n",
    "ln$track()  # track a run of your notebook or script\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "\n",
    "ln.track()  # track the current notebook or script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling {meth}`~lamindb.track`, the notebook gets automatically linked as the source of all data that's about to be saved! You can see all your transforms and their runs in the {class}`~lamindb.Transform` and {class}`~lamindb.Run` registries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "ln.Transform.df()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "ln$Transform$df()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Transform.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "ln.Run.df()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "ln$Run$df()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Run.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What happened under the hood?\n",
    "\n",
    "1. The full run environment and imported package versions of current notebook were detected\n",
    "2. Notebook metadata was detected and stored in a {class}`~lamindb.Transform` record with a unique id\n",
    "3. Run metadata was detected and stored in a {class}`~lamindb.Run` record with a unique id\n",
    "\n",
    "The {class}`~lamindb.Transform` registry stores data transformations: scripts, notebooks, pipelines, functions.\n",
    "\n",
    "The {class}`~lamindb.Run` registry stores executions of transforms. Many runs can be linked to the same transform if executed with different context (time, user, input data, etc.).\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} How do I track a pipeline instead of a notebook?\n",
    "\n",
    "Leverage a pipeline integration, see: {doc}`/pipelines`. Or manually add code as seen below.\n",
    "\n",
    "```python\n",
    "transform = ln.Transform(name=\"My pipeline\")\n",
    "transform.version = \"1.2.0\"  # tag the version\n",
    "ln.track(transform)\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} Why should I care about tracking notebooks?\n",
    "\n",
    "Because of interactivity & humans are in the loop, most mistakes happen when using notebooks.\n",
    "\n",
    "{func}`~lamindb.track` makes notebooks & derived results reproducible & auditable, enabling to learn from mistakes.\n",
    "\n",
    "This is important as much insight generated from biological data is driven by computational biologists _interacting_ with it. An early blog post on this is [here](https://blog.lamin.ai/nbproject).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Is this compliant with OpenLineage?\n",
    "\n",
    "Yes. What OpenLineage calls a \"job\", LaminDB calls a \"transform\". What OpenLineage calls a \"run\", LaminDB calls a \"run\".\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The {class}`~lamindb.Artifact` class manages datasets & models that are stored as files, folders, or arrays. {class}`~lamindb.Artifact` is a registry to manage search, queries, validation & storage access. \n",
    "\n",
    "You can register data objects (`DataFrame`, `AnnData`, ...) and files or folders in local storage, AWS S3 (`s3://`), Google Cloud (`gs://`), Hugging Face (`hf://`), or any other file system supported by `fsspec`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at an exemplary dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "df = ln.core.datasets.small_dataset1(with_typo=True)\n",
    "df\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "df <- ln$core$datasets$small_dataset1(otype = \"DataFrame\", with_typo = TRUE)\n",
    "df\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df = ln.core.datasets.small_dataset1(with_typo=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you create an artifact from a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact = ln.Artifact.from_df(df, key=\"my_datasets/rnaseq1.parquet\").save()\n",
    "artifact.describe()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact <- ln$Artifact$from_df(df, key = \"my_datasets/rnaseq1.parquet\")$save()\n",
    "artifact$describe()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact.from_df(df, key=\"my_datasets/rnaseq1.parquet\").save()\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how you load it back into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact.load()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact$load()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace data lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can understand where an artifact comes from by looking at its {class}`~lamindb.Transform` & {class}`~lamindb.Run` records:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact.transform\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact$transform\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact.run\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact$run\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or visualize deeper data lineage with the `view_lineage()` method. Here we're only one step deep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact.view_lineage()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact$view_lineage()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::::{dropdown} Show me a more interesting example, please!\n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    "\n",
    "Explore and load the notebook from [here](https://lamin.ai/laminlabs/lamindata/transform/F4L3oC6QsZvQ0002).\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/KQmzmmLOeBN0C8Yk0003.png\" width=\"800\">\n",
    ":::\n",
    ":::{tab-item} Hub\n",
    "\n",
    "Explore data lineage interactively [here](https://lamin.ai/laminlabs/lamindata/artifact/W1AiST5wLrbNEyVq0000).\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/0bXenaC9F24iP3Iy0000.png\" width=\"800\">\n",
    ":::\n",
    "::::\n",
    "\n",
    ":::::\n",
    "\n",
    ":::{dropdown} I just want to see the transforms.\n",
    "\n",
    "```python\n",
    "artifact.transform.view_lineage()  # Python only\n",
    "```\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/b0geN1HDHXlORqMO0001.png\" width=\"400\">\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data lineage also helps to understand what a dataset is being used for. Many datasets are being used over and over for different purposes.\n",
    "\n",
    "Once you're done, at the end of your notebook or script, call {meth}`~lamindb.finish`. Here, we're not yet done so we're commenting it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "# ln.finish()  # mark run as finished, save execution report, source code & environment\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "# ln$finish()  # mark run as finished, save execution report & source code\n",
    "```\n",
    "\n",
    "If you did _not_ use RStudio's notebook mode, you have to render an HTML externally.\n",
    "\n",
    "1. Render the notebook to HTML via one of:\n",
    "\n",
    "    - In RStudio, click the \"Knit\" button\n",
    "    - From the command line, run\n",
    "\n",
    "        ```bash\n",
    "        Rscript -e 'rmarkdown::render(\"introduction.Rmd\")'\n",
    "        ```\n",
    "\n",
    "    - Use the `rmarkdown` package in R\n",
    "\n",
    "        ```r\n",
    "        rmarkdown::render(\"introduction.Rmd\")\n",
    "        ```\n",
    "\n",
    "2. Save it to your LaminDB instance via one of:\n",
    "\n",
    "    - Using the `lamin_save()` function in R\n",
    "\n",
    "        ```r\n",
    "        lamin_save(\"introduction.Rmd\")\n",
    "        ```\n",
    "\n",
    "    - Using the `lamin` CLI\n",
    "\n",
    "        ```bash\n",
    "        lamin save introduction.Rmd\n",
    "        ```\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Here is how a notebook looks on the hub.\n",
    "\n",
    "[Explore](https://lamin.ai/laminlabs/lamindata/transform/PtTXoc0RbOIq65cN).\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/RGXj5wcAf7EAc6J80003.png\" width=\"900px\">\n",
    "\n",
    "To create a new version of a notebook or script, run `lamin load` on the terminal, e.g.,\n",
    "\n",
    "```bash\n",
    "$ lamin load https://lamin.ai/laminlabs/lamindata/transform/13VINnFk89PE0004\n",
    "â†’ notebook is here: mcfarland_2020_preparation.ipynb\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like transforms, artifacts are versioned. Let's create a new version by revising the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "# keep the dataframe with a typo around - we'll need it later\n",
    "df_typo = df.copy()\n",
    "\n",
    "# fix the \"IFNJ\" typo\n",
    "df[\"perturbation\"] = df[\"perturbation\"].cat.rename_categories({\"IFNJ\": \"IFNG\"})\n",
    "\n",
    "# create a new version\n",
    "artifact = ln.Artifact.from_df(df, key=\"my_datasets/rnaseq1.parquet\").save()\n",
    "\n",
    "# see all versions of an artifact\n",
    "artifact.versions.df()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "# keep the dataframe with a typo around - we'll need it later\n",
    "df_typo <- df\n",
    "\n",
    "# fix the \"IFNJ\" typo\n",
    "levels(df$perturbation) <- c(\"DMSO\", \"IFNG\")\n",
    "df[\"sample2\", \"perturbation\"] <- \"IFNG\"\n",
    "\n",
    "# create a new version\n",
    "artifact <- ln$Artifact$from_df(df, key = \"my_datasets/rnaseq1.parquet\")$save()\n",
    "\n",
    "# see all versions of an artifact\n",
    "artifact$versions$df()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# keep the dataframe with a typo around - we'll need it later\n",
    "df_typo = df.copy()\n",
    "\n",
    "# fix the \"IFNJ\" typo\n",
    "df[\"perturbation\"] = df[\"perturbation\"].cat.rename_categories({\"IFNJ\": \"IFNG\"})\n",
    "\n",
    "# create a new version\n",
    "artifact = ln.Artifact.from_df(df, key=\"my_datasets/rnaseq1.parquet\").save()\n",
    "\n",
    "# see all versions of an artifact\n",
    "artifact.versions.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Can I also create new versions without passing `key`?\n",
    "\n",
    "That works, too, you can use `revises`:\n",
    "\n",
    "```python\n",
    "artifact_v1 = ln.Artifact.from_df(df, description=\"Just a description\").save()\n",
    "# below revises artifact_v1\n",
    "artifact_v2 = ln.Artifact.from_df(df_updated, revises=artifact_v1).save()\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "The good thing about passing `revises: Artifact` is that you don't need to worry about coming up with naming conventions for paths.\n",
    "\n",
    "The good thing about versioning based on `key` is that it's how all data versioning tools are doing it.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage files & folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a folder in the cloud that contains 3 sub-folders storing images & metadata of Iris flowers, generated in 3 subsequent studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "# we use anon=True here in case no aws credentials are configured\n",
    "ln.UPath(\"s3://lamindata/iris_studies\", anon=True).view_tree()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "# we use anon=True here in case no aws credentials are configured\n",
    "ln$UPath(\"s3://lamindata/iris_studies\", anon = True).view_tree()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# we use anon=True here in case no aws credentials are configured\n",
    "ln.UPath(\"s3://lamindata/iris_studies\", anon=True).view_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an artifact for the first sub-folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact = ln.Artifact(\"s3://lamindata/iris_studies/study0_raw_images\").save()\n",
    "artifact\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact = ln$Artifact(\"s3://lamindata/iris_studies/study0_raw_images\")$save()\n",
    "artifact\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact = ln.Artifact(\"s3://lamindata/iris_studies/study0_raw_images\").save()\n",
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see from {attr}`~lamindb.Artifact.path`, the folder was merely registered in its present storage location without copying it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact.path\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact$path\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaminDB keeps track of all your storage locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "ln.Storage.df()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "ln$Storage$df()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Storage.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cache the cloud folder locally, call {meth}`~lamindb.Artifact.cache`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "artifact.cache()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "artifact$cache()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "artifact.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is large, you might not want to download but stream it via {meth}`~lamindb.Artifact.open`. For more on this, see: {doc}`arrays`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} How do I update or delete an artifact?\n",
    "\n",
    "```\n",
    "artifact.description = \"My new description\"  # change description\n",
    "artifact.save()  # save the change to the database\n",
    "artifact.delete()  # move to trash\n",
    "artifact.delete(permanent=True)  # permanently delete\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} How do I create an artifact for a local file or folder?\n",
    "\n",
    "Source path is local:\n",
    "\n",
    "```python\n",
    "ln.Artifact(\"./my_data.fcs\", key=\"my_data.fcs\")\n",
    "ln.Artifact(\"./my_images/\", key=\"my_images\")\n",
    "```\n",
    "<br>\n",
    "\n",
    "Upon `artifact.save()`, the source path will be copied or uploaded into your instance's current storage, visible & changeable via `ln.settings.storage`.\n",
    "\n",
    "If the source path is remote _or_ already in a registered storage location (one that's registered in `ln.Storage`), `artifact.save()` will _not_ trigger a copy or upload but register the existing path.\n",
    "\n",
    "```python\n",
    "ln.Artifact(\"s3://my-bucket/my_data.fcs\")  # key is auto-populated from S3, you can optionally pass a description\n",
    "ln.Artifact(\"s3://my-bucket/my_images/\")  # key is auto-populated from S3, you can optionally pass a description\n",
    "```\n",
    "<br>\n",
    "You can use any storage location supported by `fsspec`.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} Which fields are populated when creating an artifact record?\n",
    "\n",
    "Basic fields:\n",
    "\n",
    "- `uid`: universal ID\n",
    "- `key`: a (virtual) relative path of the artifact in `storage`\n",
    "- `description`: an optional string description\n",
    "- `storage`: the storage location (the root, say, an S3 bucket or a local directory)\n",
    "- `suffix`: an optional file/path suffix\n",
    "- `size`: the artifact size in bytes\n",
    "- `hash`: a hash useful to check for integrity and collisions (is this artifact already stored?)\n",
    "- `hash_type`: the type of the hash\n",
    "- `created_at`: time of creation\n",
    "- `updated_at`: time of last update\n",
    "\n",
    "Provenance-related fields:\n",
    "\n",
    "- `created_by`: the {class}`~lamindb.User` who created the artifact\n",
    "- `run`: the {class}`~lamindb.Run` of the {class}`~lamindb.Transform` that created the artifact\n",
    "\n",
    "For a full reference, see {class}`~lamindb.Artifact`.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} What exactly happens during save?\n",
    "\n",
    "In the database: An artifact record is inserted into the `Artifact` registry. If the artifact record exists already, it's returned.\n",
    "\n",
    "In storage:\n",
    "- If the default storage is in the cloud, `.save()` triggers an upload for a local artifact.\n",
    "- If the artifact is already in a registered storage location, only the metadata of the record is saved to the `artifact` registry.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} How does LaminDB compare to a AWS S3?\n",
    "\n",
    "LaminDB provides a database on top of AWS S3 (or GCP storage, file systems, etc.).\n",
    "\n",
    "Similar to organizing files with paths, you can organize artifacts using the `key` parameter of {class}`~lamindb.Artifact`.\n",
    "\n",
    "However, you'll see that you can more conveniently query data by entities you care about: people, code, experiments, genes, proteins, cell types, etc.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} Are artifacts aware of array-like data?\n",
    "\n",
    "Yes.\n",
    "\n",
    "You can make artifacts from paths referencing array-like objects:\n",
    "\n",
    "```python\n",
    "ln.Artifact(\"./my_anndata.h5ad\", key=\"my_anndata.h5ad\")\n",
    "ln.Artifact(\"./my_zarr_array/\", key=\"my_zarr_array\")\n",
    "```\n",
    "\n",
    "Or from in-memory objects:\n",
    "\n",
    "```python\n",
    "ln.Artifact.from_df(df, key=\"my_dataframe.parquet\")\n",
    "ln.Artifact.from_anndata(adata, key=\"my_anndata.h5ad\")\n",
    "```\n",
    "\n",
    "You can open large artifacts for slicing from the cloud or load small artifacts directly into memory via:\n",
    "\n",
    "```python\n",
    "artifact.open()\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query & search registries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an overview over all artifacts in your instance, call {class}`~lamindb.models.Record.df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "ln.Artifact.df()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "ln$Artifact$df()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaminDB's central classes are registries that store records ({class}`~lamindb.models.Record` objects). If you want to see the fields of a registry, look at the class or auto-complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "ln.Artifact\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "ln$Artifact\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each registry is a table in the relational schema of the underlying database. With {func}`~lamindb.view`, you can see the latest changes to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "ln.view()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "ln$view()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Which registries have I already learned about? ðŸ¤”\n",
    "\n",
    "- {class}`~lamindb.Artifact`: datasets & models stored as files, folders, or arrays\n",
    "- {class}`~lamindb.Transform`: transforms of artifacts\n",
    "- {class}`~lamindb.Run`: runs of transforms\n",
    "- {class}`~lamindb.User`: users\n",
    "- {class}`~lamindb.Storage`: local or cloud storage locations\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every registry supports arbitrary relational queries using the class methods {class}`~lamindb.models.Record.get` and {class}`~lamindb.models.Record.filter`.\n",
    "The syntax for it is Django's query syntax.\n",
    "\n",
    "Here are some simple query examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "# get a single record (here the current notebook)\n",
    "transform = ln.Transform.get(key=\"introduction.ipynb\")\n",
    "\n",
    "# get a set of records by filtering for a directory (LaminDB treats directories like AWS S3, as the prefix of the storage key)\n",
    "ln.Artifact.filter(key__startswith=\"my_datasets/\").df()\n",
    "\n",
    "# query all artifacts ingested from a transform\n",
    "artifacts = ln.Artifact.filter(transform=transform).all()\n",
    "\n",
    "# query all artifacts ingested from a notebook with \"intro\" in the title\n",
    "artifacts = ln.Artifact.filter(\n",
    "    transform__description__icontains=\"intro\",\n",
    ").all()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "# get a single record (here the current notebook)\n",
    "transform <- ln$Transform$get(key = \"introduction.Rmd\")\n",
    "\n",
    "# get a set of records by filtering for a directory (LaminDB treats directories like AWS S3, as the prefix of the storage key)\n",
    "ln$Artifact$filter(key__startswith = \"my_datasets/\")$df()\n",
    "\n",
    "# query all artifacts ingested from a transform\n",
    "artifacts <- ln$Artifact$filter(transform = transform)$all()\n",
    "\n",
    "# query all artifacts ingested from a notebook with \"intro\" in the title\n",
    "artifacts <- ln$Artifact$filter(\n",
    "  transform__description__icontains = \"intro\",\n",
    ")$all()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# get a single record (here the current notebook)\n",
    "transform = ln.Transform.get(key=\"introduction.ipynb\")\n",
    "\n",
    "# get a set of records by filtering for a directory (LaminDB treats directories like AWS S3, as the prefix of the storage key)\n",
    "ln.Artifact.filter(key__startswith=\"my_datasets/\").df()\n",
    "\n",
    "# query all artifacts ingested from a transform\n",
    "artifacts = ln.Artifact.filter(transform=transform).all()\n",
    "\n",
    "# query all artifacts ingested from a notebook with \"intro\" in the title\n",
    "artifacts = ln.Artifact.filter(\n",
    "    transform__description__icontains=\"intro\",\n",
    ").all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What does a double underscore mean?\n",
    "\n",
    "For any field, the double underscore defines a comparator, e.g.,\n",
    "\n",
    "* `name__icontains=\"Martha\"`: `name` contains `\"Martha\"` when ignoring case\n",
    "* `name__startswith=\"Martha\"`: `name` starts with `\"Martha`\n",
    "* `name__in=[\"Martha\", \"John\"]`: `name` is `\"John\"` or `\"Martha\"`\n",
    "\n",
    "For more info, see: {doc}`registries`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Can I chain filters and searches?\n",
    "\n",
    "Yes: `ln.Artifact.filter(suffix=\".jpg\").search(\"my image\")`\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class methods {class}`~lamindb.models.Record.search` and {class}`~lamindb.models.Record.lookup` help with approximate matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "# search artifacts\n",
    "ln.Artifact.search(\"iris\").df().head()\n",
    "\n",
    "# search transforms\n",
    "ln.Transform.search(\"intro\").df()\n",
    "\n",
    "# look up records with auto-complete\n",
    "ulabels = ln.ULabel.lookup()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "# search artifacts\n",
    "ln$Artifact$search(\"iris\")$df()\n",
    "\n",
    "# search transforms\n",
    "ln$Transform$search(\"intro\")$df()\n",
    "\n",
    "# look up records with auto-complete\n",
    "ulabels = ln$ULabel$lookup()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Show me a screenshot\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/lgRNHNtMxjU0y8nIagt7.png\" width=\"400px\">\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info, see: {doc}`registries`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features & labels\n",
    "\n",
    "Features & labels make it easier to find datasets and help standardizing them so that they're re-usable by analysts and machine learning models alike. Features are measurement dimensions (e.g. `\"species\"`, `\"temperature\"`) and labels are measured values (e.g. `\"human\"`, `\"mouse\"`). In stats, a feature is a variable while a label is a category.\n",
    "\n",
    ":::{dropdown} Can you give me examples for what findability and usability means?\n",
    "\n",
    "1. Findability: Which datasets measured expression of cell marker `CD14`? Which characterized cell line `K562`? Which have a test & train split? Etc.\n",
    "2. Usability: Are there typos in feature names? Are there typos in labels? Are types and units of features consistent? Etc.\n",
    "\n",
    ":::\n",
    "\n",
    "Let's annotate an artifact with a {class}`~lamindb.ULabel`, a built-in universal label ontology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "# create & save a typed label\n",
    "experiment_type = ln.ULabel(name=\"InVitroStudy\", is_type=True).save()\n",
    "my_experiment = ln.ULabel(name=\"My experiment\", type=experiment_type).save()\n",
    "\n",
    "# annotate the artifact with a label\n",
    "artifact.ulabels.add(my_experiment)\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "# create & save a typed label\n",
    "experiment_type = ln$ULabel(name=\"InVitroStudy\", is_type=True)$save()\n",
    "my_experiment = ln$ULabel(name=\"My experiment\", type=experiment_type)$save()\n",
    "\n",
    "# annotate the artifact with a label\n",
    "artifact$ulabels$add(my_experiment)\n",
    "\n",
    "# describe the artifact\n",
    "artifact$describe()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# create & save a typed ulabel\n",
    "experiment_type = ln.ULabel(name=\"InVitroStudy\", is_type=True).save()\n",
    "my_experiment = ln.ULabel(name=\"My experiment\", type=experiment_type).save()\n",
    "\n",
    "# annotate the artifact with a ulabel\n",
    "artifact.ulabels.add(my_experiment)\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you query artifacts by ulabels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "ln.Artifact.filter(ulabels=my_experiment).df()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "ln$Artifact$filter(ulabels=my_experiment)$df()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.filter(ulabels=my_experiment).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also label based on another module, like the biological ontologies in the bionty module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "import bionty as bt\n",
    "\n",
    "# create a cell type label from the source ontology\n",
    "cell_type = bt.CellType.from_source(name=\"effector T cell\").save()\n",
    "\n",
    "# annotate the artifact with a cell type\n",
    "artifact.cell_types.add(cell_type)\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "bt <- import_module(\"bionty\")\n",
    "\n",
    "# create a cell type label from the source ontology\n",
    "cell_type <- bt$CellType$from_source(name = \"effector T cell\")$save()\n",
    "\n",
    "# annotate the artifact with a cell type\n",
    "artifact$cell_types$add(cell_type)\n",
    "\n",
    "# describe the artifact\n",
    "artifact$describe()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import bionty as bt\n",
    "\n",
    "# create a cell type label from the source ontology\n",
    "cell_type = bt.CellType.from_source(name=\"effector T cell\").save()\n",
    "\n",
    "# annotate the artifact with a cell type\n",
    "artifact.cell_types.add(cell_type)\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to annotate by non-categorical metadata or indicate the feature for a label, annotate via features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Py\n",
    ":sync: python\n",
    "```python\n",
    "# define the \"temperature\" & \"experiment\" features\n",
    "ln.Feature(name=\"temperature\", dtype=float).save()\n",
    "ln.Feature(name=\"experiment\", dtype=ln.ULabel).save()\n",
    "\n",
    "# annotate the artifact\n",
    "artifact.features.add_values({\"temperature\": 21.6, \"experiment\": \"My experiment\"})\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    ":sync: r\n",
    "```R\n",
    "# define the \"temperature\" & \"experiment\" features\n",
    "ln$Feature(name = \"temperature\", dtype = \"float\")$save()\n",
    "ln$Feature(name = \"experiment\", dtype = ln$ULabel)$save()\n",
    "\n",
    "# annotate the artifact\n",
    "artifact$features$add_values(\n",
    "  list(\"temperature\" = 21.6, \"experiment\" = \"My experiment\")\n",
    ")\n",
    "\n",
    "# describe the artifact\n",
    "artifact$describe()\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# define the \"temperature\" & \"experiment\" features\n",
    "ln.Feature(name=\"temperature\", dtype=float).save()\n",
    "ln.Feature(name=\"experiment\", dtype=ln.ULabel).save()\n",
    "\n",
    "# annotate the artifact\n",
    "artifact.features.add_values({\"temperature\": 21.6, \"experiment\": \"My experiment\"})\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate datasets\n",
    "\n",
    "You already saw how to ingest datasets without validation.\n",
    "This is often enough if you're prototyping or working with one-off studies.\n",
    "But if you want to create a big body of standardized data, you have to invest the time to curate your datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a {class}`~lamindb.Schema` to curate a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# define valid labels\n",
    "perturbation_type = ln.ULabel(name=\"Perturbation\", is_type=True).save()\n",
    "ln.ULabel(name=\"DMSO\", type=perturbation_type).save()\n",
    "ln.ULabel(name=\"IFNG\", type=perturbation_type).save()\n",
    "\n",
    "# define the schema\n",
    "schema = ln.Schema(\n",
    "    name=\"My DataFrame schema\",\n",
    "    features=[\n",
    "        ln.Feature(name=\"ENSG00000153563\", dtype=int).save(),\n",
    "        ln.Feature(name=\"ENSG00000010610\", dtype=int).save(),\n",
    "        ln.Feature(name=\"ENSG00000170458\", dtype=int).save(),\n",
    "        ln.Feature(name=\"perturbation\", dtype=ln.ULabel).save(),\n",
    "    ],\n",
    ").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a `Curator`, we can save an _annotated_ & _validated_ artifact with a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "curator = ln.curators.DataFrameCurator(df, schema)\n",
    "\n",
    "# save curated artifact\n",
    "artifact = curator.save_artifact(key=\"my_curated_dataset.parquet\")  # calls .validate()\n",
    "\n",
    "# see the parsed annotations\n",
    "artifact.describe()\n",
    "\n",
    "# query for a ulabel that was parsed from the dataset\n",
    "ln.Artifact.get(ulabels__name=\"IFNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feed a dataset with an invalid dtype or typo, we'll get a `ValidationError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "curator = ln.curators.DataFrameCurator(df_typo, schema)\n",
    "\n",
    "# validate the dataset\n",
    "try:\n",
    "    curator.validate()\n",
    "except ln.errors.ValidationError as error:\n",
    "    print(str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage biological registries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generic {class}`~lamindb.Feature` and {class}`~lamindb.ULabel` registries will get you pretty far.\n",
    "\n",
    "But let's now look at what you do can with a dedicated biological registry like {class}`~bionty.Gene`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every {py:mod}`bionty` registry is based on configurable public ontologies (>20 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import bionty as bt\n",
    "\n",
    "cell_types = bt.CellType.public()\n",
    "cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "cell_types.search(\"gamma-delta T cell\").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an `AnnData` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define var schema\n",
    "var_schema = ln.Schema(\n",
    "    name=\"my_var_schema\",\n",
    "    itype=bt.Gene.ensembl_gene_id,\n",
    "    dtype=int,\n",
    ").save()\n",
    "\n",
    "obs_schema = ln.Schema(\n",
    "    name=\"my_obs_schema\",\n",
    "    features=[\n",
    "        ln.Feature(name=\"perturbation\", dtype=ln.ULabel).save(),\n",
    "    ],\n",
    ").save()\n",
    "\n",
    "# define composite schema\n",
    "anndata_schema = ln.Schema(\n",
    "    name=\"my_anndata_schema\",\n",
    "    otype=\"AnnData\",\n",
    "    components={\"obs\": obs_schema, \"var\": var_schema},\n",
    ").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate & annotate an `AnnData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import bionty as bt\n",
    "\n",
    "# store the dataset as an AnnData object to distinguish data from metadata\n",
    "adata = ad.AnnData(\n",
    "    df[[\"ENSG00000153563\", \"ENSG00000010610\", \"ENSG00000170458\"]],\n",
    "    obs=df[[\"perturbation\"]],\n",
    ")\n",
    "\n",
    "# save curated artifact\n",
    "curator = ln.curators.AnnDataCurator(adata, anndata_schema)\n",
    "artifact = curator.save_artifact(description=\"my RNA-seq\")\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for typed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# get a lookup object for human genes\n",
    "genes = bt.Gene.filter(organism__name=\"human\").lookup()\n",
    "# query for all feature sets that contain CD8A\n",
    "feature_sets = ln.FeatureSet.filter(genes=genes.cd8a).all()\n",
    "# write the query\n",
    "ln.Artifact.filter(feature_sets__in=feature_sets).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update ontologies, e.g., create a cell type record and add a new cell state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# create an ontology-coupled cell type record and save it\n",
    "neuron = bt.CellType.from_source(name=\"neuron\").save()\n",
    "\n",
    "# create a record to track a new cell state\n",
    "new_cell_state = bt.CellType(\n",
    "    name=\"my neuron cell state\", description=\"explains X\"\n",
    ").save()\n",
    "\n",
    "# express that it's a neuron state\n",
    "new_cell_state.parents.add(neuron)\n",
    "\n",
    "# view ontological hierarchy\n",
    "new_cell_state.view_parents(distance=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you integrate new datasets with your existing datasets? Leverage {class}`~lamindb.Collection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# a new dataset\n",
    "df2 = ln.core.datasets.small_dataset2(otype=\"DataFrame\")\n",
    "adata = ad.AnnData(\n",
    "    df2[[\"ENSG00000153563\", \"ENSG00000010610\", \"ENSG00000004468\"]],\n",
    "    obs=df2[[\"perturbation\"]],\n",
    ")\n",
    "curator = ln.curators.AnnDataCurator(adata, anndata_schema)\n",
    "artifact2 = curator.save_artifact(key=\"my_datasets/my_rnaseq2.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a collection using {class}`~lamindb.Collection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "collection = ln.Collection([artifact, artifact2], key=\"my-RNA-seq-collection\").save()\n",
    "collection.describe()\n",
    "collection.view_lineage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# if it's small enough, you can load the entire collection into memory as if it was one\n",
    "collection.load()\n",
    "\n",
    "# typically, it's too big, hence, open it for streaming (if the backend allows it)\n",
    "# collection.open()\n",
    "\n",
    "# or iterate over its artifacts\n",
    "collection.artifacts.all()\n",
    "\n",
    "# or look at a DataFrame listing the artifacts\n",
    "collection.artifacts.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly train models on collections of `AnnData`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# to train models, batch iterate through the collection as if it was one array\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "dataset = collection.mapped(obs_keys=[\"cell_medium\"])\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=dataset.get_label_weights(\"cell_medium\"), num_samples=len(dataset)\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=2, sampler=sampler)\n",
    "for batch in data_loader:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this [blog post](https://lamin.ai/blog/arrayloader-benchmarks) for more on training models on sharded datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
