{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![stars](https://img.shields.io/github/stars/laminlabs/lamindb?logo=GitHub&color=yellow)](https://github.com/laminlabs/lamindb)\n",
    "[![pypi](https://img.shields.io/pypi/v/lamindb?color=blue&label=pypi%20package)](https://pypi.org/project/lamindb)\n",
    "[![cran](https://www.r-pkg.org/badges/version/laminr?color=green)](https://cran.r-project.org/package=laminr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Biological data are often poorly organized. \n",
    "It's often difficult to reproduce analytical results or understand how a dataset was processed. \n",
    "And it's typically hard to apply models to historical data, orthogonal assays, or datasets generated by other teams.\n",
    "\n",
    "LaminDB is an open-source framework that makes working with biological datasets more robust, scalable, and understandable.\n",
    "Instead of managing datasets with nested file systems, a LaminDB instance provides a database with metadata structures to organize files, folders, and arrays across any number of storage locations.\n",
    "\n",
    ":::{dropdown} LaminDB specs\n",
    "\n",
    "```{include} includes/features-lamindb.md\n",
    "```\n",
    ":::\n",
    "\n",
    "LaminHub is a data collaboration hub built on LaminDB similar to how GitHub is built on git.\n",
    "\n",
    ":::{dropdown} LaminHub overview\n",
    "\n",
    "```{include} includes/features-laminhub.md\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "Install the `lamindb` Python package.\n",
    "\n",
    "```shell\n",
    "# install with support for notebooks, biological entities & AWS\n",
    "pip install 'lamindb[jupyter,bionty,aws]'\n",
    "```\n",
    "\n",
    "Connect to a LaminDB instance.\n",
    "\n",
    "```shell\n",
    "lamin connect account/instance  # <-- replace with your instance\n",
    "```\n",
    "\n",
    "Access an input dataset and save an output dataset.\n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Python\n",
    "```python\n",
    "import lamindb as ln\n",
    "\t\n",
    "ln.track()  # track a run for a notebook or script \n",
    "artifact = ln.Artifact.get(\"3TNCsZZcnIBv2WGb0001\")  # get an artifact record\n",
    "artifact.describe()   # show metadata of artifact\n",
    "df = artifact.load()  # load artifact into memory, e.g., a DataFrame\n",
    "\n",
    "# work with the dataset\n",
    "\n",
    "ln.Artifact(\"./my_result_folder\", description=\"My result\").save()  # save a folder\n",
    "ln.finish()  # mark the run as finished\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    "\n",
    "```R\n",
    "install.packages(\"laminr\", dependencies = TRUE)  # install the R package\n",
    "library(laminr)\n",
    "\n",
    "db <- connect()  # create an instance object\n",
    "db$track(path = \"./my-analysis.Rmd\")  # track your .Rmd, .R or .qmd code\n",
    "artifact <- db$Artifact$get(\"KBW89Mf7IGcekja2hADu\")\n",
    "adata <- artifact$load() # load the dataset into memory\n",
    "\n",
    "# work with the dataset\n",
    "\n",
    "db$Artifact(\"./my_result_folder\", description=\"My result\").save()\n",
    "db$finish()  # soon\n",
    "```\n",
    "\n",
    "Save an html export for `.qmd` or `.Rmd` file as a report.\n",
    "\n",
    "```shell\n",
    "lamin save my-analysis.Rmd\n",
    "```\n",
    "\n",
    "For more, see the  [R docs](https://laminr.lamin.ai/).\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaminDB instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LaminDB instance is a single relational database that manages metadata for datasets across any number of storage locations, conforming to LaminDB's schema management. You can readily create a local instance to manage data in a local folder.\n",
    "Here, you create one that mounts schema module {py:mod}`bionty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# manage artifacts in local directory `./lamin-intro`\n",
    "!lamin init --storage ./lamin-intro --schema bionty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also connect your cloud storage locations (S3, GCP, R2, HuggingFace, etc.) and databases (Postgres & SQLite). See {doc}`setup`.\n",
    "If you decide to connect your LaminDB instance to LaminHub, you will see data & metadata in a GUI.\n",
    "\n",
    "<a href=\"https://lamin.ai/laminlabs/lamindata\">\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/YuefPQlAfeHcQvtq0000.png\" width=\"700px\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "\n",
    "A data transformation (a \"transform\") is any piece of code (script, notebook, pipeline, function) that can be applied to input data to produce output data.\n",
    "When you call {meth}`~lamindb.track`, you register a transform in the {class}`~lamindb.Transform` registry, starting to auto-track inputs and outputs, with each run stored in {class}`~lamindb.Run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "\n",
    "# --> `ln.track()` generates a uid for your code\n",
    "# --> `ln.track(uid)` initiates a tracked run\n",
    "ln.track(\"FPnfDtJz8qbE0000\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Is this compliant with OpenLineage?\n",
    "\n",
    "Yes. What OpenLineage calls a \"job\", LaminDB calls a \"transform\". What OpenLineage calls a \"run\", LaminDB calls a \"run\".\n",
    "\n",
    ":::\n",
    "\n",
    ":::{dropdown} What is the `uid`?\n",
    "\n",
    "To tie a piece of code to a record in a database in a way that survives name and content changes, you need to attach it to an immutable identifier, e.g., LaminDB's `uid`.\n",
    "\n",
    "git, by comparison, identifies code by its content hash & file name. If you rename a notebook or script file and change the content, you lose the identity of the file. \n",
    "\n",
    "To version transforms, LaminDB generates `uid = f\"{stem_uid}{version_suffix}\"` so that different versions of a transform are grouped by a \"stem uid\" while the last four `uid` characters encoding its version. All versioned entities in LaminDB are versioned in this way, including artifacts and collections.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An {class}`~lamindb.Artifact` stores a dataset or model as a file, folder or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# a sample dataset\n",
    "df = pd.DataFrame(\n",
    "    {\"CD8A\": [1, 2, 3], \"CD4\": [3, 4, 5], \"CD14\": [5, 6, 7], \"perturbation\": [\"DMSO\", \"IFNJ\", \"DMSO\"],},\n",
    "    index=[\"sample1\", \"sample2\", \"sample3\"],\n",
    ")\n",
    "\n",
    "# create & save an artifact from a DataFrame -- delete via artifact.delete(permanent=True)\n",
    "artifact = ln.Artifact.from_df(df, description=\"my RNA-seq\").save()\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the artifact into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View data lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact.view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} How do I create an artifact for a file or folder?\n",
    "\n",
    "Source path is local:\n",
    "\n",
    "```python\n",
    "ln.Artifact(\"./my_data.fcs\", description=\"my flow cytometry file\")\n",
    "ln.Artifact(\"./my_images/\", description=\"my folder of images\")\n",
    "```\n",
    "<br>\n",
    "\n",
    "Upon `artifact.save()`, the source path will be copied or uploaded into your instance's current default storage.\n",
    "\n",
    "If the source path is remote or already in a registered storage location, `artifact.save()` won't trigger data duplication but register the existing path.\n",
    "\n",
    "```python\n",
    "ln.Artifact(\"s3://my-bucket/my_data.fcs\", description=\"my flow cytometry file\")\n",
    "ln.Artifact(\"s3://my-bucket/my_images/\", description=\"my folder of images\")\n",
    "```\n",
    "<br>\n",
    "You can also use other remote file systems supported by `fsspec`.\n",
    "\n",
    ":::\n",
    "\n",
    "```{dropdown} How does LaminDB compare to a AWS S3?\n",
    "\n",
    "LaminDB provides a relational metadata layer on top of AWS S3 (or GCP storage, file system, etc.).\n",
    "\n",
    "Similar to organizing files in file systems & object stores with paths, you can organize artifacts using the `key` parameter of {class}`~lamindb.Artifact`.\n",
    "However, LaminDB encourages you to **not** rely on semantic keys but instead organize your data based on metadata.\n",
    "\n",
    "Rather than memorizing names of folders and files, you find data via the entities you care about: people, code, experiments, genes, proteins, cell types, etc.\n",
    "\n",
    "LaminDB indexes artifacts in storage via the `uid`.\n",
    "This scales much better than semantic keys, which lead to deep hierarchical information structures that can become hard to navigate.\n",
    "\n",
    "Because metadata is typed and relational, you can work with more structure, more integrity, and richer queries compared to leveraging S3's JSON-like metadata.\n",
    "You'll learn more about this below.\n",
    "\n",
    "```\n",
    "\n",
    ":::{dropdown} Are artifacts aware of array-like data?\n",
    "\n",
    "Yes.\n",
    "\n",
    "You can make artifacts from paths referencing array-like objects:\n",
    "\n",
    "```python\n",
    "ln.Artifact(\"./my_anndata.h5ad\", description=\"curated array\")\n",
    "ln.Artifact(\"./my_zarr_array/\", description=\"my zarr array store\")\n",
    "```\n",
    "\n",
    "Or from in-memory objects:\n",
    "\n",
    "```python\n",
    "ln.Artifact.from_df(df, description=\"my dataframe\")\n",
    "ln.Artifact.from_anndata(adata, description=\"annotated array\")\n",
    "```\n",
    "\n",
    "You can open large artifacts for slicing from the cloud or load small artifacts directly into memory.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like transforms, artifacts are versioned. Let's create a new version by revising the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# keep the dataframe with a typo around - we'll need it later\n",
    "df_typo = df.copy()\n",
    "\n",
    "# fix the \"IFNJ\" typo\n",
    "df.loc[\"sample2\", \"perturbation\"] = \"IFNG\"\n",
    "\n",
    "# create a new version by revising the artifact\n",
    "artifact = ln.Artifact.from_df(df, revises=artifact).save()\n",
    "\n",
    "# see all versions of an artifact\n",
    "artifact.versions.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} I'd rather control versioning through a key or file path like on S3.\n",
    "\n",
    "That works, too, and you won't need to pass an old version via `revises`:\n",
    "\n",
    "```python\n",
    "artifact_v1 = ln.Artifact.from_df(df, key=\"my_datasets/my_study1.parquet\").save()\n",
    "# below automatically creates a new version of artifact_v1 because the `key` matches\n",
    "artifact_v2 = ln.Artifact.from_df(df_updated, key=\"my_datasets/my_study1.parquet\").save()\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "The good thing about passing `revises: Artifact` is that it works for entities that don't come with a file path and you don't need to worry about coming up with naming conventions for paths.\n",
    "You'll see that LaminDB makes it easy to organize data by entities, rather than file paths.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label\n",
    "\n",
    "Label an artifact with a {class}`~lamindb.ULabel` and a {class}`bionty.CellType`. The same works for any entity in any custom schema module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import bionty as bt\n",
    "\n",
    "# create & save a ulabel record\n",
    "candidate_marker_study = ln.ULabel(name=\"Candidate marker study\").save()\n",
    "\n",
    "# label the artifact\n",
    "artifact.ulabels.add(candidate_marker_study)\n",
    "\n",
    "# repeat for a bionty entity\n",
    "cell_type = bt.CellType.from_source(name=\"effector T cell\").save()\n",
    "artifact.cell_types.add(cell_type)\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaminDB's central classes are registries that store records ({class}`~lamindb.core.Record` objects).\n",
    "We've already seen how to create new `artifact`, `transform` and `ulabel` records.\n",
    "\n",
    "The easiest way to see the latest records of a given type is to call the _class method_ {class}`~lamindb.core.Record.df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.ULabel.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing records are stored in the record's registry (metaclass {class}`~lamindb.core.Registry`), which maps 1:1 to a SQL table.\n",
    "\n",
    "A record and its registry share the same fields, which define the metadata you can query for. If you want to see them, look at the class or auto-complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query & search\n",
    "\n",
    "You can write arbitrary relational queries using the class methods {class}`~lamindb.core.Record.get` and {class}`~lamindb.core.Record.filter`.\n",
    "The syntax for it is Django's query syntax, one of the two most popular ORMs in Python (the other is SQLAlchemy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single record by uid (here, the latest version of the current notebook)\n",
    "transform = ln.Transform.get(\"FPnfDtJz8qbE\")\n",
    "\n",
    "# get a single record by matching a field\n",
    "transform = ln.Transform.get(name=\"Introduction\")\n",
    "\n",
    "# get a set of records by filtering on description\n",
    "ln.Artifact.filter(description=\"my RNA-seq\").df()\n",
    "\n",
    "# query all artifacts ingested from the current notebook\n",
    "artifacts = ln.Artifact.filter(transform=transform).all()\n",
    "\n",
    "# query all artifacts ingested from a notebook with \"intro\" in the name and labeled \"Candidate marker study\"\n",
    "artifacts = ln.Artifact.filter(\n",
    "    transform__name__icontains=\"intro\", ulabels=candidate_marker_study\n",
    ").all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class methods {class}`~lamindb.core.Record.search` and {class}`~lamindb.core.Record.lookup` help finding sets of approximately matching records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in a registry\n",
    "ln.Transform.search(\"intro\").df()\n",
    "\n",
    "# look up records with auto-complete\n",
    "ulabels = ln.ULabel.lookup()\n",
    "cell_types = bt.CellType.lookup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} Show me a screenshot\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/lgRNHNtMxjU0y8nIagt7.png\" width=\"400px\">\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fields are to metadata records, features are to datasets.\n",
    "You can annotate datasets by the features they measure.\n",
    "\n",
    "But because LaminDB validates all user input against its registries, annotating with a `\"temperature\"` feature doesn't work right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "with pytest.raises(ln.core.exceptions.ValidationError) as e:\n",
    "    artifact.features.add_values({\"temperature\": 21.6})\n",
    "\n",
    "print(e.exconly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the hint in the error message, create & save a {class}`~lamindb.Feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# create & save the \"temperature\" feature (only required once)\n",
    "ln.Feature(name=\"temperature\", dtype=\"float\").save()\n",
    "\n",
    "# now we can annotate with the feature & the value\n",
    "artifact.features.add_values({\"temperature\": 21.6})\n",
    "\n",
    "# describe the artifact\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also annotate with categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# register a categorical feature\n",
    "ln.Feature(name=\"study\", dtype=\"cat\").save()\n",
    "\n",
    "# add a categorical value\n",
    "artifact.features.add_values({\"study\": \"Candidate marker study\"})\n",
    "\n",
    "# describe the artifact with type information\n",
    "artifact.describe(print_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you query artifacts by features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.Artifact.features.filter(study__contains=\"marker study\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features organize labels by how they're measured in datasets, independently of how labels are stored in metadata registries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand data lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand where a dataset comes from and what it's used for ([background](inv:docs#project-flow)).\n",
    "\n",
    "```python\n",
    "artifact.view_lineage()\n",
    "```\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/KQmzmmLOeBN0C8Ykitjn.svg\" width=\"800\">\n",
    "\n",
    ":::{dropdown} I just want to see the transformations.\n",
    "\n",
    "```python\n",
    "transform.view_lineage()\n",
    "```\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/b0geN1HDHXlORqMOOPay.svg\" width=\"400\">\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need a workflow manager to track data lineage (if you want to use one, see {doc}`docs:pipelines`). All you need is:\n",
    "\n",
    "```python\n",
    "import lamindb as ln\n",
    "\n",
    "ln.track()  # track your run\n",
    "\n",
    "# your code\n",
    "\n",
    "ln.finish()  # mark run as finished, save execution report, source code & environment\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is how a single transform ([a notebook](https://lamin.ai/laminlabs/lamindata/transform/PtTXoc0RbOIq65cN)) with its run report looks on the hub.\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/RGXj5wcAf7EAc6J8dJfH.png\" width=\"900px\">\n",
    "\n",
    "To create a new version of a notebook or script, run `lamin load` on the terminal, e.g.,\n",
    "\n",
    "```bash\n",
    "$ lamin load https://lamin.ai/laminlabs/lamindata/transform/13VINnFk89PE0004\n",
    "→ connected lamindb: laminlabs/lamindata\n",
    "→ updated uid: 13VINnFk89PE0004 → 13VINnFk89PE0005\n",
    "→ notebook is here: mcfarland_2020_preparation.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curate datasets\n",
    "\n",
    "In the quickstart, you just saw how to ingest & annotate datasets without validation.\n",
    "This is often enough if you're prototyping or working with one-off studies.\n",
    "But if you want to create a big body of standardized data, you have to invest the time to curate your datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a {class}`~lamindb.Curator` object to curate a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# construct a Curator object to validate & annotate a DataFrame\n",
    "curator = ln.Curator.from_df(\n",
    "    df,\n",
    "    # define validation criteria as mappings\n",
    "    columns=ln.Feature.name,  # map column names\n",
    "    categoricals={\"perturbation\": ln.ULabel.name},  # map categories\n",
    ")\n",
    "\n",
    "# validate the dataset\n",
    "curator.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation did not pass because LaminDB's registries don't yet know about the features `\"CD8A\", \"CD4\", \"CD14\", \"perturbation\"` and labels `\"DMSO\", \"IFNG\", \"DMSO\"` in this dataset.\n",
    "Hence, we need to initially populate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# add non-validated features based on the DataFrame columns\n",
    "curator.add_new_from_columns()\n",
    "\n",
    "# add non-validated labels based on the perturbation column of the dataframe\n",
    "curator.add_new_from(\"perturbation\")\n",
    "\n",
    "# see the updated content of the ULabel registry\n",
    "ln.ULabel.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the {class}`~lamindb.ULabel` and {class}`~lamindb.Feature` registries now containing meaningful reference values, validation passes & and we can automatically parse features & labels to save an _annotated_ & _curated_ artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# given the updated registries, the validation passes\n",
    "curator.validate()\n",
    "\n",
    "# save curated artifact\n",
    "artifact = curator.save_artifact(description=\"my RNA-seq\")\n",
    "\n",
    "# see the parsed annotations\n",
    "artifact.describe()\n",
    "\n",
    "# query for a ulabel that was parsed from the dataset\n",
    "ln.Artifact.get(ulabels__name=\"IFNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had we used `ln.Cuartor` from the beginning, we would have caught the typo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# construct a Curator object to validate & annotate a DataFrame\n",
    "curator = ln.Curator.from_df(\n",
    "    df_typo,\n",
    "    columns=ln.Feature.name,\n",
    "    categoricals={\"perturbation\": ln.ULabel.name},\n",
    ")\n",
    "\n",
    "# validate the dataset\n",
    "curator.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage biological registries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generic {class}`~lamindb.Feature` and {class}`~lamindb.ULabel` registries will get you pretty far.\n",
    "\n",
    "But let's now look at what you do can with a dedicated biological registry like {class}`~bionty.Gene`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every {py:mod}`bionty` registry is based on configurable public ontologies (>20 of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "cell_types = bt.CellType.public()\n",
    "cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "cell_types.search(\"gamma delta T cell\").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate & annotate with typed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "\n",
    "# store the dataset as an AnnData object to distinguish data from metadata\n",
    "adata = ad.AnnData(\n",
    "    df[[\"CD8A\", \"CD4\", \"CD14\"]], obs=df[[\"perturbation\"]]\n",
    ")\n",
    "\n",
    "# create an annotation flow for an AnnData object\n",
    "curate = ln.Curator.from_anndata(\n",
    "    adata,\n",
    "    # define validation criteria\n",
    "    var_index=bt.Gene.symbol,  # map .var.index onto Gene registry\n",
    "    categoricals={adata.obs.perturbation.name: ln.ULabel.name},\n",
    "    organism=\"human\",  # specify the organism for the Gene registry\n",
    ")\n",
    "curate.validate()\n",
    "\n",
    "# save curated artifact\n",
    "artifact = curate.save_artifact(description=\"my RNA-seq\")\n",
    "artifact.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for typed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# get a lookup object for human genes\n",
    "genes = bt.Gene.filter(organism__name=\"human\").lookup()\n",
    "# query for all feature sets that contain CD8A\n",
    "feature_sets = ln.FeatureSet.filter(genes=genes.cd8a).all()\n",
    "# write the query\n",
    "ln.Artifact.filter(feature_sets__in=feature_sets).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update ontologies, e.g., create a cell type record and add a new cell state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# create an ontology-coupled cell type record and save it\n",
    "neuron = bt.CellType.from_source(name=\"neuron\").save()\n",
    "\n",
    "# create a record to track a new cell state\n",
    "new_cell_state = bt.CellType(name=\"my neuron cell state\", description=\"explains X\").save()\n",
    "\n",
    "# express that it's a neuron state\n",
    "new_cell_state.parents.add(neuron)\n",
    "\n",
    "# view ontological hierarchy\n",
    "new_cell_state.view_parents(distance=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you integrate new datasets with your existing datasets? Leverage {class}`~lamindb.Collection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# a new dataset\n",
    "df = pd.DataFrame(\n",
    "    {\"CD8A\": [2, 3, 3], \"CD4\": [3, 4, 5], \"CD38\": [4, 2, 3], \"perturbation\": [\"DMSO\", \"IFNG\", \"IFNG\"],},\n",
    "    index=[\"sample4\", \"sample5\", \"sample6\"],\n",
    ")\n",
    "adata = ad.AnnData(df[[\"CD8A\", \"CD4\", \"CD38\"]], obs=df[[\"perturbation\"]])\n",
    "\n",
    "# validate, curate and save a new artifact\n",
    "curate = ln.Curator.from_anndata(\n",
    "    adata,\n",
    "    var_index=bt.Gene.symbol,\n",
    "    categoricals={adata.obs.perturbation.name: ln.ULabel.name},\n",
    "    organism=\"human\",\n",
    ")\n",
    "curate.validate()\n",
    "artifact2 = curate.save_artifact(description=\"my RNA-seq dataset 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a collection using {class}`~lamindb.Collection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "collection = ln.Collection([artifact, artifact2], name=\"my RNA-seq collection\").save()\n",
    "collection.describe()\n",
    "collection.view_lineage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# if it's small enough, you can load the entire collection into memory as if it was one\n",
    "collection.load()\n",
    "\n",
    "# typically, it's too big, hence, iterate over its artifacts\n",
    "collection.artifacts.all()\n",
    "\n",
    "# or look at a DataFrame listing the artifacts\n",
    "collection.artifacts.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly train models on collections of `AnnData`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# to train models, batch iterate through the collection as if it was one array\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "dataset = collection.mapped(obs_keys=[\"perturbation\"])\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=dataset.get_label_weights(\"perturbation\"), num_samples=len(dataset)\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=2, sampler=sampler)\n",
    "for batch in data_loader:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this [blog post](https://lamin.ai/blog/arrayloader-benchmarks) for more on training models on sharded datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design\n",
    "\n",
    "### Why?\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/BunYmHkyFLITlM5MYQck.svg\" width=\"350px\" style=\"background: transparent\" align=\"right\">\n",
    "\n",
    "Objects like `pd.DataFrame` are at the heart of many data science workflows but there hasn't been a tool to manage these objects in the rich context that collaborative biological research requires:\n",
    "\n",
    "- data lineage: data sources, data transformations, models, users\n",
    "- domain knowledge & experimental metadata: the features & labels derived from domain entities\n",
    "\n",
    "In this [blog post](https://lamin.ai/blog/problems), we discuss how the complexity of modern R&D data often blocks realizing the scientific progress it promises.\n",
    "\n",
    "### World model\n",
    "\n",
    "1. Teams need to have enough freedom to initiate work independently but enough structure to easily integrate datasets later on\n",
    "2. Batched datasets ({class}`~lamindb.Artifact`) from physical instruments are transformed ({class}`~lamindb.Transform`) into useful representations\n",
    "3. Learning needs features ({class}`~lamindb.Feature`, {class}`~bionty.CellMarker`, ...) and labels ({class}`~lamindb.ULabel`, {class}`~bionty.CellLine`, ...)\n",
    "4. Insights connect dataset representations with experimental metadata and knowledge (ontologies)\n",
    "\n",
    "### Architecture\n",
    "\n",
    "LaminDB is a distributed system like git that can be run or hosted anywhere. As infrastructure, you merely need a database (SQLite/Postgres) and a storage location (file system, S3, GCP, HuggingFace, ...).\n",
    "\n",
    "You can easily create your new local instance:\n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Shell\n",
    "```bash\n",
    "lamin init --storage ./my-data-folder\n",
    "```\n",
    ":::\n",
    ":::{tab-item} Python\n",
    "```python\n",
    "import lamindb as ln\n",
    "ln.setup.init(storage=\"./my-data-folder\")\n",
    "```\n",
    ":::\n",
    "::::\n",
    "\n",
    "Or you can let collaborators connect to a cloud-hosted instance:\n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Shell\n",
    "```bash\n",
    "lamin connect account-handle/instance-name\n",
    "```\n",
    ":::\n",
    ":::{tab-item} Python\n",
    "```python\n",
    "import lamindb as ln\n",
    "ln.connect(\"account-handle/instance-name\")\n",
    "```\n",
    ":::\n",
    ":::{tab-item} R\n",
    "```R\n",
    "library(laminr)\n",
    "ln <- connect(\"account-handle/instance-name\")\n",
    "```\n",
    ":::\n",
    "::::\n",
    "\n",
    "For learning more about how to create & host LaminDB instances on distributed infrastructure, see {doc}`setup`. LaminDB instances work standalone but can optionally be managed by LaminHub. For an architecture diagram of LaminHub, [reach out](https://lamin.ai/contact)!\n",
    "\n",
    "\n",
    "### Metada schema & API\n",
    "\n",
    "<img src=\"https://lamin-site-assets.s3.amazonaws.com/.lamindb/XoTQFCmmj2uU4d2xyj9u.png\" width=\"350px\" style=\"background: transparent\" align=\"right\">\n",
    "\n",
    "LaminDB provides a SQL schema for common metadata entities: {class}`~lamindb.Artifact`, {class}`~lamindb.Collection`, {class}`~lamindb.Transform`, {class}`~lamindb.Feature`, {class}`~lamindb.ULabel` etc. - see the [API reference](/api) or the [source code](https://github.com/laminlabs/lnschema-core/blob/main/lnschema_core/models.py).\n",
    "\n",
    "The core metadata schema is extendable through plugins (see green vs. red entities in **graphic**), e.g., with basic biological ({class}`~bionty.Gene`, {class}`~bionty.Protein`, {class}`~bionty.CellLine`, etc.) & operational entities (`Biosample`, `Techsample`, `Treatment`, etc.).\n",
    "\n",
    "```{dropdown} What is the metadata schema language?\n",
    "\n",
    "Data models are defined in Python using the Django ORM. Django translates them to SQL tables.\n",
    "[Django](https://github.com/django/django) is one of the most-used & highly-starred projects on GitHub (~1M dependents, ~73k stars) and has been robustly maintained for 15 years.\n",
    "\n",
    "```\n",
    "\n",
    "On top of the metadata schema, LaminDB is a Python API that models datasets as artifacts, abstracts over storage & database access, data transformations, and (biological) ontologies.\n",
    "\n",
    "Note that the datasets schema (e.g., `.parquet` files or `.h5ad` arrays) is modeled through the `Feature` registry and does not require migrations to be updated.\n",
    "\n",
    "### Custom schemas and plugins\n",
    "\n",
    "LaminDB can be customized & extended with schema & app plugins building on the [Django](https://github.com/django/django) ecosystem. Examples are:\n",
    "\n",
    "- [bionty](./bionty): Registries for basic biological entities, coupled to public ontologies.\n",
    "- [wetlab](https://github.com/laminlabs/wetlab): Registries for samples, treatments, etc.\n",
    "\n",
    "If you'd like to create your own schema or app:\n",
    "\n",
    "1. Create a git repository with registries similar to [wetlab](https://github.com/laminlabs/wetlab)\n",
    "2. Create & deploy migrations via `lamin migrate create` and `lamin migrate deploy`\n",
    "\n",
    "### Repositories\n",
    "\n",
    "LaminDB and its plugins consist in open-source Python libraries & publicly hosted metadata assets:\n",
    "\n",
    "- [lamindb](https://github.com/laminlabs/lamindb): Core package.\n",
    "- [bionty](https://github.com/laminlabs/bionty): Registries for basic biological entities, coupled to public ontologies.\n",
    "- [wetlab](https://github.com/laminlabs/wetlab): Registries for samples, treatments, etc.\n",
    "- [usecases](https://github.com/laminlabs/lamin-usecases): Use cases as visible on the docs.\n",
    "\n",
    "All immediate dependencies are available as git submodules [here](https://github.com/laminlabs/lamindb/tree/main/sub), for instance,\n",
    "\n",
    "- [lnschema-core](https://github.com/laminlabs/lnschema-core): Core schema.\n",
    "- [lamindb-setup](https://github.com/laminlabs/lamindb-setup): Setup & configure LaminDB.\n",
    "- [lamin-cli](https://github.com/laminlabs/lamin-cli): CLI for `lamindb` and `lamindb-setup`.\n",
    "\n",
    "For a comprehensive list of open-sourced software, browse our [GitHub account](https://github.com/laminlabs).\n",
    "\n",
    "- [lamin-utils](https://github.com/laminlabs/lamin-utils): Generic utilities, e.g., a logger.\n",
    "- [readfcs](https://github.com/laminlabs/readfcs): FCS artifact reader.\n",
    "- [nbproject](https://github.com/laminlabs/readfcs): Light-weight Jupyter notebook tracker.\n",
    "- [bionty-assets](https://github.com/laminlabs/bionty-assets): Assets for public biological ontologies.\n",
    "\n",
    "LaminHub is not open-sourced.\n",
    "\n",
    "### Influences\n",
    "\n",
    "LaminDB was influenced by many other projects, see {doc}`docs:influences`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
