LaminDB is an open-source data framework to enable learning at scale in computational biology.
It lets you track data transformations, curate datasets, manage metadata, and query a built-in database for biological entities & data structures.

:::{dropdown} Why?

Reproducing analytical results or understanding how a dataset or model was created can be a pain.
Leave alone training models on historical data, orthogonal assays, or datasets generated by other teams.

Biological datasets are typically managed with versioned storage systems (file systems, object storage, git, dvc), {term}`UI`-focused community or SaaS platforms, structureless data lakes, rigid data warehouses (SQL, monolithic arrays), and data lakehouses for tabular data.

LaminDB goes beyond these systems with a lakehouse that models biological datasets beyond tables with enough structure to enable queries and enough freedom to keep the pace of R&D high.

For data structures like `DataFrame`, `AnnData`, `.zarr`, `.tiledbsoma`, etc., LaminDB tracks and provides the rich context that collaborative biological research requires:

- data lineage: data sources and transformations; scientists and machine learning models
- domain knowledge and experimental metadata: the features and labels derived from domain entities

In this [blog post](https://lamin.ai/blog/problems), we discuss a breadth of data management problems of the field.

:::

:::{dropdown} LaminDB specs

```{include} includes/features-lamindb.md

```

:::

LaminHub is a data collaboration hub built on LaminDB similar to how GitHub is built on git.

:::{dropdown} LaminHub overview

```{include} includes/features-laminhub.md

```

:::

## Quickstart

::::{tab-set}
:::{tab-item} Python
:sync: python

For setup, install the `lamindb` Python package and connect to a LaminDB instance.

```shell
pip install 'lamindb[jupyter,bionty]'  # support notebooks & biological ontologies
lamin login  # <-- you can skip this for public, local & self-hosted instances
lamin connect account/instance  # <-- replace with your instance
```

In your Python session, you access an input dataset and save an output dataset.

```python
import lamindb as ln

ln.track()  # track a run of your notebook or script
artifact = ln.Artifact.get("3TNCsZZcnIBv2WGb0001")  # get an artifact by uid
filepath = artifact.cache()  # cache the artifact on disk

# do your work

ln.Artifact("./my_dataset.csv", key="my_results/my_dataset.csv").save()  # save a file
ln.finish()  # mark the run as finished & save a report for the current notebook/script
```

:::
:::{tab-item} R
:sync: r

For setup, install the `laminr` and `lamindb` packages and connect to a LaminDB instance.

```R
install.packages("laminr", dependencies = TRUE)  # install the laminr package from CRAN
laminr::install_lamindb(extra_packages = c("bionty"))  # install lamindb & bionty for use via reticulate
laminr::lamin_login()  # <-- you can skip this for public, local, and self-hosted instances
laminr::lamin_connect("<account>/<instance>")  # <-- replace with your instance
```

In your R session, you access an input dataset and save an output dataset.

```R
library(laminr)
ln <- import_module("lamindb")  # instantiate the central object of the API

# Access inputs

ln$track()  # track your run of a notebook or script
artifact <- ln$Artifact$using("laminlabs/cellxgene")$get("7dVluLROpalzEh8m")  # https://lamin.ai/laminlabs/cellxgene/artifact/7dVluLROpalzEh8m
adata <- artifact$load()  # load the artifact into memory or sync to cache via filepath <- artifact$cache()

# Your transformation

library(Seurat)  # find marker genes with Seurat
seurat_obj <- CreateSeuratObject(counts = as(Matrix::t(adata$X), "CsparseMatrix"), meta.data = adata$obs)
seurat_obj[["RNA"]] <- AddMetaData(GetAssay(seurat_obj), adata$var)
Idents(seurat_obj) <- "cell_type"
seurat_obj <- NormalizeData(seurat_obj)
markers <- FindAllMarkers(seurat_obj, features = Features(seurat_obj)[1:100])
seurat_path <- tempfile(fileext = ".rds")
saveRDS(seurat_obj, seurat_path)

# Save outputs

ln$Artifact(seurat_path, key = "my-datasets/my-seurat-object.rds")$save()
ln$Artifact$from_df(markers, key = "my-datasets/my-markers.parquet")$save()
ln$finish()  # finish the run, save source code & run report
```

If you did _not_ use RStudio's notebook mode, create an html export and run the following on the CLI.

```shell
lamin save my-analysis.Rmd  #  save source code and html report for a `.qmd` or `.Rmd` file
```

:::
::::
